{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b407b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard\n",
    "from datetime import datetime\n",
    "from typing import Final\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "\n",
    "from tabrel.benchmark.nw_regr import Mlp, MlpConfig, generate_multidim_noisy_data, make_random_r, train_nw_arbitrary, NwModelConfig, RelNwRegr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd89d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples: Final[int] = 300\n",
    "seed: Final[int] = 42\n",
    "x_dim: Final[int] = 7\n",
    "n_epochs: Final[int] = 5000\n",
    "\n",
    "# mse, r2, _, _ = train_nw_arbitrary(\n",
    "#     x_backgnd=x_np[back_ids],\n",
    "#     y_backgnd=y_np[back_ids],\n",
    "#     x_query=x_np[query_ids],\n",
    "#     y_query=y_np[query_ids],\n",
    "#     x_val=x_np[val_ids],\n",
    "#     y_val=y_np[val_ids],\n",
    "#     r_query_backgnd=r[query_ids][:, back_ids],\n",
    "#     r_val_nonval=r[val_ids][:, train_ids],\n",
    "#     cfg=NwModelConfig(input_dim=x_dim, trainable_weights_matrix=True,),\n",
    "#     lr=1e-3,\n",
    "#     n_epochs=n_epochs\n",
    "# )\n",
    "\n",
    "# print(mse, r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cfe17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabrel.benchmark.nw_regr import train_nw_mlp\n",
    "\n",
    "def train_nw_mlp_synthetic(\n",
    "        seed: int,\n",
    "        mlp_hid_dim: int,\n",
    "        mlp_out_dim: int,\n",
    "        dropout: float,\n",
    "        weight_decay: float,\n",
    "        writer: SummaryWriter | None,\n",
    "        trainable_weights: bool = False,\n",
    "        _n_epochs: int = n_epochs,\n",
    "        ) -> tuple[float, float]:\n",
    "    x_np, y_np, c = generate_multidim_noisy_data(n_samples, n_clusters=3, x_dim=x_dim, seed=seed)\n",
    "    r = make_random_r(seed, c)\n",
    "\n",
    "    n_query = n_back = n_samples // 3\n",
    "    n_train = n_query + n_back\n",
    "    n_val = n_samples - n_train\n",
    "    back_ids = np.arange(n_back)\n",
    "    query_ids = np.arange(n_query) + n_back\n",
    "    val_ids = np.arange(n_val) + n_train\n",
    "\n",
    "    return train_nw_mlp(\n",
    "        x=x_np,\n",
    "        y=y_np,\n",
    "        r=r,\n",
    "        back_ids=back_ids,\n",
    "        query_ids=query_ids,\n",
    "        val_ids=val_ids,\n",
    "        mlp_hid_dim=mlp_hid_dim,\n",
    "        mlp_out_dim=mlp_out_dim,\n",
    "        dropout=dropout,\n",
    "        weight_decay=weight_decay,\n",
    "        _n_epochs=_n_epochs,\n",
    "        writer=writer,\n",
    "        trainable_weights=trainable_weights,\n",
    "        seed=seed,\n",
    "    )\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24646be",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir: Final[str] = \"tb_logs\" + datetime.isoformat(datetime.now()).replace(\":\", \"_\")\n",
    "print(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a57d093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir {log_dir}\n",
    "\n",
    "# writer = SummaryWriter(log_dir=log_dir)\n",
    "# train_nw_mlp_synthetic(\n",
    "#     seed=seed,\n",
    "#     mlp_hid_dim=64,\n",
    "#     mlp_out_dim=6,\n",
    "#     dropout=.2,\n",
    "#     weight_decay=1e-4,\n",
    "#     writer=writer)\n",
    "\n",
    "mses, r2s = [], []\n",
    "for _seed in range(15):\n",
    "    # mse, r2 = train_nw_mlp_synthetic(\n",
    "    #     seed=_seed,\n",
    "    #     weight_decay=0.0006913422,\n",
    "    #     mlp_hid_dim=8,\n",
    "    #     mlp_out_dim=20,\n",
    "    #     dropout=0.09302061,\n",
    "    #     trainable_weights=False,\n",
    "    #     writer=None,\n",
    "    # )\n",
    "    # dim 6:\n",
    "    # 0.23309 var 0.00074\n",
    "    # 0.81283 var 0.00048\n",
    "    # dim 7:\n",
    "    # 0.08264 var 0.00061\n",
    "    # 0.93438 var 0.00047\n",
    "\n",
    "    mse, r2 = train_nw_mlp_synthetic(\n",
    "        seed=_seed,\n",
    "        weight_decay=0.002,\n",
    "        mlp_hid_dim=10,\n",
    "        mlp_out_dim=20,\n",
    "        dropout=.19,\n",
    "        _n_epochs=n_epochs,\n",
    "        trainable_weights=False,\n",
    "        writer=None,\n",
    "    )\n",
    "    # dim 6:\n",
    "    # 0.23555 var 0.00118\n",
    "    # 0.81012 var 0.00048\n",
    "\n",
    "    # dim 7:\n",
    "    # 0.07144 var 0.00020\n",
    "    # 0.94344 var 0.00017\n",
    "    mses.append(mse)\n",
    "    r2s.append(r2)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "for metrics in (mses, r2s):\n",
    "    print(f\"{np.mean(metrics):.5f} var {np.var(metrics):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9134147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 0., 1e-2)\n",
    "    mlp_hid_dim = trial.suggest_int(\"mlp_hid_dim\", 6, 100)\n",
    "    mlp_out_dim = trial.suggest_int(\"mlp_out_dim\", 1, 20)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0., .5)\n",
    "    val_r2 = train_nw_mlp_synthetic(\n",
    "        seed=seed,\n",
    "        mlp_hid_dim=mlp_hid_dim,\n",
    "        mlp_out_dim=mlp_out_dim,\n",
    "        dropout=dropout,\n",
    "        weight_decay=weight_decay,\n",
    "        writer=None,\n",
    "    )[1]\n",
    "    return val_r2\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", study_name=f\"r_random_{datetime.now()}\", storage=\"sqlite:///db.sqlite3\")\n",
    "study.optimize(objective)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ba0e74",
   "metadata": {},
   "source": [
    "code for loading an existing trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e86e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    storage=\"sqlite:///db.sqlite3\",\n",
    "    study_name=\"r_deterministic_2025-11-07 14:52:56.356900\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "# study.optimize(objective, n_trials=10)\n",
    "print(f\"Best trial: {study.best_trial}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00de955",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b79da3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir {log_dir} \n",
    "\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "train_nw_mlp_synthetic(\n",
    "    seed=seed,\n",
    "    mlp_hid_dim=study.best_params[\"mlp_hid_dim\"],\n",
    "    mlp_out_dim=study.best_params[\"mlp_out_dim\"],\n",
    "    dropout=study.best_params[\"dropout\"],\n",
    "    weight_decay=study.best_params[\"weight_decay\"],\n",
    "    writer=writer,\n",
    "    _n_epochs = 10_000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4d4f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO transform Y (with another MLP?)\n",
    "# TODO embeddings AND learnable norm (+ weight decay?)\n",
    "# TODO try RTDL num embeddings instead of or before perceptrons\n",
    "# TODO another synthetic?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabrel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
