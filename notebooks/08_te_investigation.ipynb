{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b514d9e2",
   "metadata": {},
   "source": [
    "Why biased $\\tau$ estimates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8e86ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from typing import Final\n",
    "\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from tabrel.utils.treatment import load_ihdp_data, generate_indices\n",
    "\n",
    "\n",
    "ihdp_data, ihdp_exclude_cols, ihdp_tau_colname, _, _, _ = load_ihdp_data(Path(\"../CEVAE/datasets/IHDP\"))\n",
    "x_all = ihdp_data.drop(columns=ihdp_exclude_cols + [ihdp_tau_colname])\n",
    "\n",
    "\n",
    "def split_treated_non_treated(x: pd.DataFrame, treatment: np.ndarray, y_fact: pd.DataFrame) -> tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    treated = treatment == 1\n",
    "    x_treated, y_treated = x.loc[treated], y_fact.loc[treated]\n",
    "    x_non_treated, y_non_treated = x.loc[~treated], y_fact.loc[~treated]\n",
    "    return x_treated.to_numpy(), y_treated.to_numpy(), x_non_treated.to_numpy(), y_non_treated.to_numpy()\n",
    "\n",
    "\n",
    "y_fact_colname, y_cfact_colname = \"y_factual\", \"y_cfactual\"\n",
    "data_y_fact, data_y_cfact, data_treatment = ihdp_data[y_fact_colname], ihdp_data[y_cfact_colname], ihdp_data[\"treatment\"]\n",
    "\n",
    "\n",
    "y_s = data_y_fact.to_numpy() # Y for S-learner\n",
    "y_s_cfact = data_y_cfact.to_numpy()\n",
    "treatment_np = data_treatment.to_numpy()\n",
    "tau_true = ihdp_data[ihdp_tau_colname].to_numpy()\n",
    "\n",
    "lr, n_epochs = 1e-3, 50\n",
    "lgb_params: Final[dict[str, str | int]] = {\"objective\": \"regression\", \"metric\": \"rmse\", \"verbosity\": -1}\n",
    "\n",
    "x_s = x_all\n",
    "x_len = len(x_all)\n",
    "\n",
    "x_s[\"treatment\"] = data_treatment\n",
    "x_s_np = x_s.to_numpy()\n",
    "n_samples, n_feats = x_s_np.shape\n",
    "\n",
    "seed: Final[int] = 42\n",
    "np.random.seed(seed)\n",
    "ids_q, ids_b, ids_v = generate_indices(seed, n_total=x_len)\n",
    "ids_train = np.concatenate((ids_q, ids_b))\n",
    "xb, yb, xq, yq = x_s_np[ids_b], y_s[ids_b], x_s_np[ids_q], y_s[ids_q]\n",
    "xv, yv, yv_cfact, treatment_v = x_s_np[ids_v], y_s[ids_v], y_s_cfact[ids_v], treatment_np[ids_v]\n",
    "n_val = len(xv)\n",
    "\n",
    "yv = np.concatenate([yv, yv_cfact])\n",
    "xv_cfact = xv.copy()\n",
    "xv_cfact[:, -1] = 1 - treatment_v # assuming treatment is the last col\n",
    "xv = np.concatenate([xv, xv_cfact])\n",
    "x_s_np = np.concatenate([x_s_np[:len(x_s)], xv_cfact])\n",
    "y_s = np.concatenate([y_s[:len(x_s)], yv_cfact])\n",
    "tau_val_true = tau_true[ids_v]\n",
    "ids_v = np.concatenate([ids_v, np.arange(start=len(x_s), stop=len(ids_v) + len(x_s))])\n",
    "\n",
    "x_train = np.concatenate([xq, xb])\n",
    "y_train = np.concatenate([yq, yb])\n",
    "lgb_model = lgb.train(lgb_params, lgb.Dataset(x_train, label=y_train))\n",
    "y_pred_lgb = lgb_model.predict(xv)\n",
    "\n",
    "y_lgb_fact, y_lgb_cfact = y_pred_lgb[:n_val], y_pred_lgb[n_val:]\n",
    "tau_lgb_pred = (y_lgb_fact - y_lgb_cfact) * (-1) ** (1 - treatment_v)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.title(f\"LGB seed {seed}\")\n",
    "plt.plot(range(len(tau_val_true)), tau_val_true, label=\"tau validate true\")\n",
    "plt.plot(range(len(tau_lgb_pred)), tau_lgb_pred, label = \"tau val LGB\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d861c26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87fdf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import hdbscan\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import umap.umap_ as umap\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "\n",
    "x_notreatment = x_all.drop(columns=[\"treatment\"])\n",
    "X_feat = x_notreatment.T  # shape: (n_features x n_samples)\n",
    "scaler = StandardScaler()\n",
    "X_feat_scaled = scaler.fit_transform(X_feat)  # np.array, shape (n_features, n_samples)\n",
    "\n",
    "Z = linkage(X_feat_scaled, method='ward')\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "dendrogram(\n",
    "    Z,\n",
    "    labels=x_notreatment.columns, \n",
    "    leaf_rotation=90,\n",
    "    leaf_font_size=8,\n",
    ")\n",
    "plt.title(\"Feature dendrogram\")\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30febc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0787f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_feat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098d28f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaled = scaler.fit_transform(x_all[[\"x1\", \"x2\", \"x14\", \"x16\", \"x18\"]])\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=30)\n",
    "clusters = clusterer.fit_predict(x_scaled)\n",
    "np.unique(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5c91b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabrel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
