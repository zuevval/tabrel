{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9889f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Final\n",
    "from pathlib import Path\n",
    "\n",
    "CACHE_DIR: Final[Path] = Path('~/.cache/us_maps').resolve()\n",
    "CACHE_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "\n",
    "def plot_us_state_choropleth(\n",
    "    df: pd.DataFrame,\n",
    "    value_col: str,\n",
    "    cmap: str = 'OrRd',\n",
    "    set_col: str | None = None,\n",
    "    cache_dir: Path = CACHE_DIR,\n",
    "    out_path: Path | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots a U.S. state choropleth map with optional border color coding by set.\n",
    "\n",
    "    Parameters:\n",
    "    - df: Pandas DataFrame with state names (index) and a statistics column.\n",
    "    - value_col: Name of the statistics column.\n",
    "    - cmap: Matplotlib colormap to use (default: 'OrRd').\n",
    "    - set_col: Optional column name for border coloring with values: 'train', 'test', 'val'.\n",
    "    - cache_dir: Directory to store or load the cached GeoJSON.\n",
    "    - out_path: Optional output path (pdf, png, etc) for the figure\n",
    "    \"\"\"\n",
    "    geojson_path = cache_dir / 'us_states.geojson'\n",
    "\n",
    "    if not geojson_path.exists():\n",
    "        url = 'https://raw.githubusercontent.com/jgoodall/us-maps/master/geojson/state.geo.json'\n",
    "        print(\"Downloading U.S. states GeoJSON...\")\n",
    "        import requests\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        with geojson_path.open('wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(\"Done downloading\")\n",
    "\n",
    "    usa_states = gpd.read_file(geojson_path)\n",
    "\n",
    "    # Normalize index casing\n",
    "    df = df.copy()\n",
    "    df.index = df.index.str.title()\n",
    "\n",
    "    # Rename and merge\n",
    "    usa_states = usa_states.rename(columns={'NAME10': 'state'})\n",
    "    merged = usa_states.set_index('state').join(df)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "\n",
    "    # Base plot\n",
    "    # Plot without legend\n",
    "    merged.plot(column=value_col, cmap=cmap, linewidth=0.8, ax=ax, edgecolor='0.8', legend=False)\n",
    "\n",
    "    # Create scalar mappable for colorbar\n",
    "    norm = mpl.colors.Normalize(vmin=merged[value_col].min(), vmax=merged[value_col].max())\n",
    "    sm = mpl.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "\n",
    "    # Add smaller colorbar\n",
    "    fig.colorbar(sm, ax=ax, fraction=0.025, pad=0.04)\n",
    "    linewidth: Final[float] = 2.5\n",
    "\n",
    "    if set_col and set_col in merged.columns:\n",
    "        # Color mappings for 'train', 'test', 'val'\n",
    "        set_colors = {'train': 'blue', 'test': 'green', 'val': 'orange'}\n",
    "\n",
    "        for set_value, color in set_colors.items():\n",
    "            subset = merged[merged[set_col] == set_value]\n",
    "            if not subset.empty:\n",
    "                subset.boundary.plot(ax=ax, edgecolor=color, linewidth=linewidth)\n",
    "\n",
    "        # Add legend boxes as text annotations with background color\n",
    "        ax.text(0.1, 0.24, \n",
    "                'train', \n",
    "                transform=ax.transAxes, \n",
    "                fontsize=14,\n",
    "                bbox=dict(facecolor=\"white\", edgecolor=set_colors[\"train\"], boxstyle=\"round,pad=0.3\", alpha=0.8, linewidth=linewidth),\n",
    "                )\n",
    "\n",
    "        ax.text(0.1, 0.17, \n",
    "                'test', \n",
    "                transform=ax.transAxes, \n",
    "                fontsize=14,\n",
    "                bbox=dict(facecolor=\"white\", edgecolor=set_colors[\"test\"], boxstyle=\"round,pad=0.3\", alpha=0.8, linewidth=linewidth)\n",
    "                )\n",
    "\n",
    "        ax.text(0.1, 0.1, \n",
    "                'validate',\n",
    "                transform=ax.transAxes, \n",
    "                fontsize=14,\n",
    "                bbox=dict(facecolor=\"white\", edgecolor=set_colors[\"val\"], boxstyle=\"round,pad=0.3\", alpha=0.8, linewidth=linewidth),\n",
    "                )\n",
    "\n",
    "    ax.set_title(f'U.S. States Colored by {value_col}', fontsize=16)\n",
    "    ax.axis('off')\n",
    "    if out_path:\n",
    "        plt.savefig(out_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed716d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_borders = {\n",
    "        'Alabama': ['Florida', 'Georgia', 'Mississippi', 'Tennessee'],\n",
    "        'Alaska': [],\n",
    "        'Arizona': ['California', 'Colorado', 'Nevada', 'New Mexico', 'Utah'],\n",
    "        'Arkansas': ['Louisiana', 'Mississippi', 'Missouri', 'Oklahoma', 'Tennessee', 'Texas'],\n",
    "        'California': ['Arizona', 'Nevada', 'Oregon'],\n",
    "        'Colorado': ['Arizona', 'Kansas', 'Nebraska', 'New Mexico', 'Oklahoma', 'Utah', 'Wyoming'],\n",
    "        'Connecticut': ['Massachusetts', 'New York', 'Rhode Island'],\n",
    "        'Delaware': ['Maryland', 'New Jersey', 'Pennsylvania'],\n",
    "        'Florida': ['Alabama', 'Georgia'],\n",
    "        'Georgia': ['Alabama', 'Florida', 'North Carolina', 'South Carolina', 'Tennessee'],\n",
    "        'Hawaii': [],\n",
    "        'Idaho': ['Montana', 'Nevada', 'Oregon', 'Utah', 'Washington', 'Wyoming'],\n",
    "        'Illinois': ['Indiana', 'Iowa', 'Michigan', 'Kentucky', 'Missouri', 'Wisconsin'],\n",
    "        'Indiana': ['Illinois', 'Kentucky', 'Michigan', 'Ohio'],\n",
    "        'Iowa': ['Illinois', 'Minnesota', 'Missouri', 'Nebraska', 'South Dakota', 'Wisconsin'],\n",
    "        'Kansas': ['Colorado', 'Missouri', 'Nebraska', 'Oklahoma'],\n",
    "        'Kentucky': ['Illinois', 'Indiana', 'Missouri', 'Ohio', 'Tennessee', 'Virginia', 'West Virginia'],\n",
    "        'Louisiana': ['Arkansas', 'Mississippi', 'Texas'],\n",
    "        'Maine': ['New Hampshire'],\n",
    "        'Maryland': ['Delaware', 'Pennsylvania', 'Virginia', 'West Virginia'],\n",
    "        'Massachusetts': ['Connecticut', 'New Hampshire', 'New York', 'Rhode Island', 'Vermont'],\n",
    "        'Michigan': ['Illinois', 'Indiana', 'Minnesota', 'Ohio', 'Wisconsin'],\n",
    "        'Minnesota': ['Iowa', 'Michigan', 'North Dakota', 'South Dakota', 'Wisconsin'],\n",
    "        'Mississippi': ['Alabama', 'Arkansas', 'Louisiana', 'Tennessee'],\n",
    "        'Missouri': ['Arkansas', 'Illinois', 'Iowa', 'Kansas', 'Kentucky', 'Nebraska', 'Oklahoma', 'Tennessee'],\n",
    "        'Montana': ['Idaho', 'North Dakota', 'South Dakota', 'Wyoming'],\n",
    "        'Nebraska': ['Colorado', 'Iowa', 'Kansas', 'Missouri', 'South Dakota', 'Wyoming'],\n",
    "        'Nevada': ['Arizona', 'California', 'Idaho', 'Oregon', 'Utah'],\n",
    "        'New Hampshire': ['Maine', 'Massachusetts', 'Vermont'],\n",
    "        'New Jersey': ['Delaware', 'New York', 'Pennsylvania'],\n",
    "        'New Mexico': ['Arizona', 'Colorado', 'Oklahoma', 'Texas', 'Utah'],\n",
    "        'New York': ['Connecticut', 'Massachusetts', 'New Jersey', 'Pennsylvania', 'Vermont'],\n",
    "        'North Carolina': ['Georgia', 'South Carolina', 'Tennessee', 'Virginia'],\n",
    "        'North Dakota': ['Minnesota', 'Montana', 'South Dakota'],\n",
    "        'Ohio': ['Indiana', 'Kentucky', 'Michigan', 'Pennsylvania', 'West Virginia'],\n",
    "        'Oklahoma': ['Arkansas', 'Colorado', 'Kansas', 'Missouri', 'New Mexico', 'Texas'],\n",
    "        'Oregon': ['California', 'Idaho', 'Nevada', 'Washington'],\n",
    "        'Pennsylvania': ['Delaware', 'Maryland', 'New Jersey', 'New York', 'Ohio', 'West Virginia'],\n",
    "        'Rhode Island': ['Connecticut', 'Massachusetts'],\n",
    "        'South Carolina': ['Georgia', 'North Carolina'],\n",
    "        'South Dakota': ['Iowa', 'Minnesota', 'Montana', 'Nebraska', 'North Dakota', 'Wyoming'],\n",
    "        'Tennessee': ['Alabama', 'Arkansas', 'Georgia', 'Kentucky', 'Mississippi', 'Missouri', 'North Carolina', 'Virginia'],\n",
    "        'Texas': ['Arkansas', 'Louisiana', 'New Mexico', 'Oklahoma'],\n",
    "        'Utah': ['Arizona', 'Colorado', 'Idaho', 'Nevada', 'New Mexico', 'Wyoming'],\n",
    "        'Vermont': ['Massachusetts', 'New Hampshire', 'New York'],\n",
    "        'Virginia': ['Kentucky', 'Maryland', 'North Carolina', 'Tennessee', 'West Virginia'],\n",
    "        'Washington': ['Idaho', 'Oregon'],\n",
    "        'West Virginia': ['Kentucky', 'Maryland', 'Ohio', 'Pennsylvania', 'Virginia'],\n",
    "        'Wisconsin': ['Illinois', 'Iowa', 'Michigan', 'Minnesota'],\n",
    "        'Wyoming': ['Colorado', 'Idaho', 'Montana', 'Nebraska', 'South Dakota', 'Utah']\n",
    "}\n",
    "\n",
    "def share_common_border_us_states(s1: str, s2: str) -> bool:\n",
    "    # Normalize inputs\n",
    "    s1 = s1.strip().title()\n",
    "    s2 = s2.strip().title()\n",
    "\n",
    "    if s1 not in state_borders or s2 not in state_borders:\n",
    "        raise ValueError(f\"State '{s1}' or '{s2}' is not a valid U.S. state\")\n",
    "\n",
    "    return s2 in state_borders[s1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7034102f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"justin2028/unemployment-in-america-per-us-state\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc0b772",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(list(Path(path).glob(\"*.csv\"))[0])\n",
    "example_year: Final[int] = 1976\n",
    "example_month: Final[int] = 1\n",
    "\n",
    "filtered_data = data[\n",
    "    data[\"State/Area\"].isin(state_borders.keys()) & \n",
    "    ~data[\"State/Area\"].isin([\"Alaska\", \"Hawaii\"])\n",
    "]\n",
    "filtered_data = filtered_data.set_index(filtered_data[\"State/Area\"])\n",
    "\n",
    "x_cols = [\"Total Civilian Labor Force in State/Area\",\n",
    "          \"Total Civilian Non-Institutional Population in State/Area\",\n",
    "          \"Percent (%) of State/Area\\'s Population\"\n",
    "          ]\n",
    "y_col = \"Percent (%) of Labor Force Employed in State/Area\"\n",
    "filtered_data[x_cols[:2]] = filtered_data[x_cols[:2]].apply(lambda col: pd.to_numeric(col.str.replace(\",\", \"\"), errors=\"coerce\"))\n",
    "\n",
    "\n",
    "def subset_month(year: int, month: int) -> pd.DataFrame:\n",
    "    data_year = filtered_data[filtered_data[\"Year\"] == year]\n",
    "    return data_year[data_year[\"Month\"] == month]\n",
    "\n",
    "\n",
    "\n",
    "data_month = subset_month(year=example_year, month=example_month)\n",
    "data_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695f7b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_us_state_choropleth(data_month, value_col=y_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc83843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "\n",
    "x_cols_short = list(range(len(x_cols)))\n",
    "renamed_data = data_month.rename(\n",
    "    columns={k:v for k, v in zip(x_cols, x_cols_short)}\n",
    ")\n",
    "sns.pairplot(renamed_data, vars=x_cols_short)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9d336f",
   "metadata": {},
   "source": [
    "First two features are almost perfectly correlated, so getting rid of the first feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909d8c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cols_reduced = x_cols[1:]\n",
    "x_cols_short_reduced = x_cols_short[1:]\n",
    "sns.scatterplot(data_month, x=x_cols_reduced[0], y=x_cols_reduced[1], hue=y_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8350e444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Northwestern US states\n",
    "test_states = [\n",
    "    \"Washington\", \"Oregon\", \"Idaho\", \"Montana\", \"Wyoming\",\n",
    "    \"North Dakota\", \"South Dakota\", \"Nebraska\", \"Minnesota\", \"Iowa\",\n",
    "    \"Colorado\", \"Utah\", \"Nevada\", \"Kansas\", \"Missouri\"\n",
    "]\n",
    "\n",
    "# Eastern US states\n",
    "val_states = [\n",
    "    \"Maine\", \"New Hampshire\", \"Vermont\", \"Massachusetts\", \"Connecticut\",\n",
    "    \"New York\", \"New Jersey\", \"Pennsylvania\", \"Delaware\", \"Maryland\",\n",
    "    \"Rhode Island\", \"Virginia\", \"North Carolina\", \"South Carolina\", \"Georgia\"\n",
    "]\n",
    "\n",
    "set_col: Final[str] = \"set\"\n",
    "data_month[set_col] = \"train\"\n",
    "data_month.loc[test_states, set_col] = \"test\"\n",
    "data_month.loc[val_states, set_col] = \"val\"\n",
    "\n",
    "plot_us_state_choropleth(data_month, value_col=y_col, set_col=set_col, out_path=Path(f\"emloyment_{example_year}_{example_month}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6ab29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from tabrel.benchmark.nw_regr import NwModelConfig, NwTrainConfig, RelNwRegr\n",
    "\n",
    "train_cfg, model_cfg = NwTrainConfig(lr=0.006, n_epochs=100), NwModelConfig()\n",
    "\n",
    "results = defaultdict(list)\n",
    "\n",
    "for year in tqdm(filtered_data[\"Year\"].unique()):\n",
    "    for month in range(1, 13):\n",
    "        data_month = subset_month(year, month)\n",
    "        if data_month.empty:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            test_indices = data_month.index.get_indexer(test_states)\n",
    "            val_indices = data_month.index.get_indexer(val_states)\n",
    "            if np.any(test_indices == -1) or np.any(val_indices == -1):\n",
    "                continue\n",
    "\n",
    "            n_samples: Final[int] = len(data_month)\n",
    "            all_indices = np.arange(n_samples)\n",
    "            nontrain_indices = np.array([*test_indices, *val_indices])\n",
    "            train_indices = np.setdiff1d(all_indices, test_indices)\n",
    "\n",
    "            x = data_month[x_cols_reduced].to_numpy()\n",
    "            y = data_month[y_col].to_numpy()\n",
    "\n",
    "            x_train = x[train_indices]\n",
    "            y_train = y[train_indices]\n",
    "            x_test = x[test_indices]\n",
    "            y_test = y[test_indices]\n",
    "            x_val = x[val_indices]\n",
    "            y_val = y[val_indices]\n",
    "\n",
    "            x_mean = np.mean(x_train, axis=0, keepdims=True)\n",
    "            x_std = np.std(x_train, axis=0, keepdims=True) + 1e-8\n",
    "\n",
    "            x_train_norm = (x_train - x_mean) / x_std\n",
    "            x_test_norm = (x_test - x_mean) / x_std\n",
    "            x_val_norm = (x_val - x_mean) / x_std\n",
    "\n",
    "            r = np.zeros((n_samples, n_samples))\n",
    "            for i, j in product(range(n_samples), range(n_samples)):\n",
    "                state_i, state_j = data_month.index[i], data_month.index[j]\n",
    "                if share_common_border_us_states(state_i, state_j):\n",
    "                    r[i, j] = 1\n",
    "\n",
    "            r_train = r[np.ix_(train_indices, train_indices)]\n",
    "            r_test_train = r[np.ix_(test_indices, train_indices)]\n",
    "\n",
    "            x_nonval_norm = np.concatenate((x_train_norm, x_test_norm))\n",
    "            y_nonval = np.concatenate((y_train, y_test))\n",
    "            r_val_nonval = r[np.ix_(val_indices, np.concatenate((train_indices, test_indices)))]\n",
    "\n",
    "            # Convert to torch\n",
    "            x_train_norm = torch.tensor(x_train_norm, dtype=torch.float32)\n",
    "            y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "            x_test_norm = torch.tensor(x_test_norm, dtype=torch.float32)\n",
    "            y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "            r_test_train = torch.tensor(r_test_train, dtype=torch.float32)\n",
    "\n",
    "            x_val_norm = torch.tensor(x_val_norm, dtype=torch.float32)\n",
    "            x_nonval_norm = torch.tensor(x_nonval_norm, dtype=torch.float32)\n",
    "            y_val = torch.tensor(y_val, dtype=torch.float32)\n",
    "            y_nonval = torch.tensor(y_nonval, dtype=torch.float32)\n",
    "            r_val_nonval = torch.tensor(r_val_nonval, dtype=torch.float32)\n",
    "\n",
    "            for use_rel in (True, False):\n",
    "                model = RelNwRegr(model_cfg)\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr=train_cfg.lr)\n",
    "                loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "                model.train()\n",
    "                for epoch in range(train_cfg.n_epochs):\n",
    "                    optimizer.zero_grad()\n",
    "                    y_pred = model(x_train_norm, y_train, x_test_norm,\n",
    "                                   r_test_train if use_rel else torch.zeros_like(r_test_train))\n",
    "                    loss = loss_fn(y_pred, y_test)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    y_pred_val = model(x_nonval_norm, y_nonval, x_val_norm,\n",
    "                                       r_val_nonval if use_rel else torch.zeros_like(r_val_nonval))\n",
    "                    y_pred_val_np = y_pred_val.numpy()\n",
    "                    y_val_np = y_val.numpy()\n",
    "\n",
    "                    mse = mean_squared_error(y_val_np, y_pred_val_np)\n",
    "                    r2 = r2_score(y_val_np, y_pred_val_np)\n",
    "\n",
    "                    results[f\"rel={use_rel}\"].append((mse, r2))\n",
    "        except Exception as e:\n",
    "            # print(f\"Skipping year={year}, month={month}: {e}\")\n",
    "            continue\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5), sharex=True)\n",
    "\n",
    "labels = list(results.keys())\n",
    "bar_locs = np.arange(len(labels))\n",
    "\n",
    "# Prepare data\n",
    "mse_means = [np.mean([x[0] for x in results[k]]) for k in labels]\n",
    "mse_stds = [np.std([x[0] for x in results[k]]) for k in labels]\n",
    "\n",
    "r2_means = [np.mean([x[1] for x in results[k]]) for k in labels]\n",
    "r2_stds = [np.std([x[1] for x in results[k]]) for k in labels]\n",
    "\n",
    "# MSE plot\n",
    "ax1.bar(bar_locs, mse_means, yerr=mse_stds, capsize=5, color='skyblue')\n",
    "ax1.set_ylabel(\"MSE (val)\")\n",
    "ax1.set_title(\"Validation MSE (mean ± std)\")\n",
    "ax1.set_xticks(bar_locs)\n",
    "ax1.set_xticklabels(labels)\n",
    "\n",
    "# R squared plot\n",
    "ax2.bar(bar_locs, r2_means, yerr=r2_stds, capsize=5, color='lightgreen')\n",
    "ax2.set_ylabel(\"$R^2$ (val)\")\n",
    "ax2.set_title(\"Validation $R^2$ (mean $\\pm$ std)\")\n",
    "ax2.set_xticks(bar_locs)\n",
    "ax2.set_xticklabels(labels)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
