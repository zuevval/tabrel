{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf789f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Final\n",
    "from itertools import combinations\n",
    "\n",
    "import kagglehub\n",
    "from pycountry import countries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import geopandas as gpd\n",
    "\n",
    "from tabrel.benchmark.nw_regr import run_training\n",
    "from tabrel.train import train_relnet\n",
    "from tabrel.utils.geo import get_connected_country_set, build_border_map, build_r_countries\n",
    "\n",
    "\n",
    "\n",
    "path = kagglehub.dataset_download(\"amirhosseinmirzaie/countries-life-expectancy\")\n",
    "df = pd.read_csv(list(Path(path).glob(\"*.csv\"))[0])\n",
    "\n",
    "class NoneCountry:\n",
    "    alpha_3 = None\n",
    "    \n",
    "df[\"ISO_alpha\"] = df[\"Country\"].apply(lambda x: countries.get(name=x, default=NoneCountry).alpha_3)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee3ac4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2015 = df[df[\"Year\"] == 2015]\n",
    "features: Final[list[str]] = [\"Hepatitis B\", \"Polio\", \"Diphtheria\", \"HIV/AIDS\", \"BMI\"]\n",
    "response: Final[str] = \"Life expectancy\"\n",
    "\n",
    "sns.pairplot(df_2015[features + [response]],hue=response)\n",
    "\n",
    "px.choropleth(\n",
    "    df_2015,\n",
    "    locations=\"ISO_alpha\",\n",
    "    color=\"Life expectancy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0cd362",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2015.set_index(\"ISO_alpha\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8cb33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "world = gpd.read_file(\"/Users/vzuev/Documents/git/gh_zuevval/tabrel/data/ne_50m_admin_0_countries/ne_50m_admin_0_countries.shp\")\n",
    "\n",
    "world = world[world['ISO_A3_EH'] != '-99']\n",
    "border_map = build_border_map(world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a9a14e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3f4a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import torch.nn as nn\n",
    "\n",
    "from tabrel.benchmark.nw_regr import NwModelConfig, RelNwRegr\n",
    "\n",
    "\n",
    "\n",
    "max_query_size = max_val_size = 40\n",
    "min_query_size = min_val_size = 10\n",
    "\n",
    "n_runs = 0\n",
    "metrics = defaultdict(list)\n",
    "\n",
    "seed: Final[int] = 42\n",
    "np.random.seed(seed)\n",
    "while n_runs < 15:\n",
    "    year = np.random.choice(df[\"Year\"])\n",
    "    df_year = df[df[\"Year\"] == year]\n",
    "    df_year.set_index(\"ISO_alpha\", inplace=True)\n",
    "    R, iso_list = build_r_countries(df_year, border_map)\n",
    "    y = df_year[response].to_numpy()\n",
    "    all_isos = set(iso_list)\n",
    "    iso_list = list(all_isos) # remove Nones\n",
    "    query_iso = np.random.choice(iso_list)  # starting node for query set\n",
    "    val_iso = np.random.choice(iso_list)  # starting node for validation set\n",
    "\n",
    "    query_set = get_connected_country_set(query_iso, border_map, max_size=max_query_size)\n",
    "    val_set = get_connected_country_set(val_iso, border_map, max_size=max_val_size)\n",
    "\n",
    "    if len(query_set) < min_query_size or len(val_set) < min_val_size:\n",
    "        continue\n",
    "\n",
    "    if query_set & val_set:\n",
    "        continue\n",
    "\n",
    "    n_runs += 1\n",
    "    backgnd_set = all_isos - query_set - val_set\n",
    "\n",
    "    backgnd_indices = np.array([i for i, iso in enumerate(iso_list) if iso in backgnd_set])\n",
    "    query_indices = np.array([i for i, iso in enumerate(iso_list) if iso in query_set])\n",
    "    val_indices = np.array([i for i, iso in enumerate(iso_list) if iso in val_set])\n",
    "\n",
    "    x_initial = df_year[\n",
    "    [\"Polio\", \"HIV/AIDS\", \"Diphtheria\", \"under-five deaths\"]\n",
    "    # [\"Alcohol\"]\n",
    "    # [\"thinness  1-19 years\"],\n",
    "    # [\"BMI\"],\n",
    "    ].to_numpy()\n",
    "\n",
    "    # torch.manual_seed(seed)\n",
    "    # results_relnet = train_relnet(\n",
    "    #     x=X,\n",
    "    #     y=y,\n",
    "    #     r=R,\n",
    "    #     backgnd_indices=np.array(backgnd_indices),\n",
    "    #     query_indices=np.array(query_indices),\n",
    "    #     val_indices=np.array(val_indices),\n",
    "    #     lr=.01,\n",
    "    #     n_epochs=1500,\n",
    "    #     periodic_embed_dim=None,\n",
    "    #     progress_bar=False,\n",
    "    #     print_loss=False,\n",
    "    #     n_layers=2,\n",
    "    #     num_heads=2,\n",
    "    #     embed_dim=8,\n",
    "    # )\n",
    "\n",
    "    n_samples, n_feats = x_initial.shape\n",
    "\n",
    "    x_extended = np.concatenate([x_initial, R], axis=1)\n",
    "\n",
    "    for x, x_label in (\n",
    "         (x_initial, \"xInit\"), \n",
    "        #  (x_extended, \"xExtended\")\n",
    "         ):\n",
    "\n",
    "        x_mean = np.mean(x, axis=0, keepdims=True)\n",
    "        x_std = np.std(x, axis=0, keepdims=True)\n",
    "        x_norm = (x - x_mean) / x_std\n",
    "\n",
    "        r_torch = torch.Tensor(R)\n",
    "        x_torch = torch.Tensor(x_norm)\n",
    "        y_torch = torch.Tensor(y)\n",
    "\n",
    "        n_back = n_query = n_samples // 3\n",
    "        n_test = n_samples - (n_back + n_query)\n",
    "        x_back, y_back = x_torch[:n_back], y_torch[:n_back]\n",
    "        x_q, y_q = x_torch[n_back : n_query + n_back], y_torch[n_back : n_query + n_back]\n",
    "        x_val, y_val = x_torch[n_back + n_query :], y_torch[n_back + n_query :]\n",
    "        r_q_b = r_torch[n_back : n_query + n_back, :n_back]\n",
    "        \n",
    "        if x_label == \"xExtended\":\n",
    "            r_q_b = torch.zeros_like(r_q_b)\n",
    "        \n",
    "        x_train, y_train = x_torch[: n_back + n_query], y_torch[: n_back + n_query]\n",
    "        r_val_train = r_torch[n_back + n_query :, : n_back + n_query]\n",
    "\n",
    "        if x_label == \"xExtended\":\n",
    "                r_val_train = torch.zeros_like(r_val_train)\n",
    "\n",
    "        # for init_sigma, init_r_scale in product(\n",
    "        #     (.1, .5, 1, 5, 10),\n",
    "        #     (.1, .5, 1, 5, 10)\n",
    "        # ):\n",
    "        \n",
    "        config = NwModelConfig(\n",
    "            init_sigma=1.0,\n",
    "            init_r_scale=1.0,\n",
    "            input_dim=n_feats if x_label == \"xInit\" else n_feats + n_samples,\n",
    "            trainable_weights_matrix=False,\n",
    "        )\n",
    "        model = RelNwRegr(config)\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "        loss_fn = nn.MSELoss()\n",
    "        torch.manual_seed(seed)\n",
    "        model.train()\n",
    "\n",
    "        try:\n",
    "            n_epochs = 1000\n",
    "            for _ in range(n_epochs):\n",
    "                optimizer.zero_grad()\n",
    "                y_pred = model(x_back, y_back, x_q, r_q_b)\n",
    "                loss = loss_fn(y_pred, y_q)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                y_pred = model(\n",
    "                    x_train,\n",
    "                    y_train,\n",
    "                    x_val,\n",
    "                    r_val_train,\n",
    "                )\n",
    "                y_pred_np = y_pred.numpy()\n",
    "                y_val_np = y_val.numpy()\n",
    "                \n",
    "                mse = mean_squared_error(y_val_np, y_pred_np)\n",
    "                r2 = r2_score(y_val_np, y_pred_np)\n",
    "                metrics[f\"{x_label}_mse\"].append(mse)\n",
    "                metrics[f\"{x_label}_r2\"].append(r2)\n",
    "        except Exception as e:\n",
    "            print(f\"exception: {e}\")\n",
    "\n",
    "\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}:\\tmean {np.mean(v):.4f}\\tstd {np.std(v):.4f}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f3e730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO try parameters grid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabrel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
