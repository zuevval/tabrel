{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf789f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Final\n",
    "from itertools import combinations\n",
    "\n",
    "import kagglehub\n",
    "from pycountry import countries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import geopandas as gpd\n",
    "\n",
    "from tabrel.benchmark.nw_regr import run_training\n",
    "from tabrel.train import train_relnet\n",
    "from tabrel.utils.geo import get_connected_country_set, build_border_map, build_r_countries\n",
    "\n",
    "\n",
    "\n",
    "path = kagglehub.dataset_download(\"amirhosseinmirzaie/countries-life-expectancy\")\n",
    "df = pd.read_csv(list(Path(path).glob(\"*.csv\"))[0])\n",
    "features: Final[list[str]] = [\"Hepatitis B\", \"Polio\", \"Diphtheria\", \"HIV/AIDS\", \"BMI\"]\n",
    "response: Final[str] = \"Life expectancy\"\n",
    "\n",
    "class NoneCountry:\n",
    "    alpha_3 = None\n",
    "    \n",
    "df[\"ISO_alpha\"] = df[\"Country\"].apply(lambda x: countries.get(name=x, default=NoneCountry).alpha_3)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc7efc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Year\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee3ac4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2015 = df[df[\"Year\"] == 2015]\n",
    "\n",
    "sns.pairplot(df_2015[features + [response]],hue=response)\n",
    "\n",
    "fig_choropleth = px.choropleth(\n",
    "    df_2015,\n",
    "    locations=\"ISO_alpha\",\n",
    "    color=\"Life expectancy\"\n",
    ")\n",
    "fig_choropleth.write_image(\"life_expectancy_choropleth.png\", width=1000, height=600, scale=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0cd362",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2015.set_index(\"ISO_alpha\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8cb33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "world = gpd.read_file(\"/Users/vzuev/Documents/git/gh_zuevval/tabrel/data/ne_50m_admin_0_countries/ne_50m_admin_0_countries.shp\")\n",
    "\n",
    "world = world[world['ISO_A3_EH'] != '-99']\n",
    "border_map = build_border_map(world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3f4a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import torch.nn as nn\n",
    "\n",
    "from tabrel.benchmark.nw_regr import NwModelConfig, RelNwRegr\n",
    "\n",
    "\n",
    "\n",
    "max_query_size = max_val_size = 40\n",
    "min_query_size = min_val_size = 10\n",
    "\n",
    "n_runs = 0\n",
    "metrics = defaultdict(list)\n",
    "\n",
    "seed: Final[int] = 42\n",
    "np.random.seed(seed)\n",
    "while n_runs < 15:\n",
    "    year = np.random.choice(df[\"Year\"])\n",
    "    df_year = df[df[\"Year\"] == year]\n",
    "    df_year.set_index(\"ISO_alpha\", inplace=True)\n",
    "    R, iso_list = build_r_countries(df_year, border_map)\n",
    "    y = df_year[response].to_numpy()\n",
    "    all_isos = set(iso_list)\n",
    "    iso_list = list(all_isos) # remove Nones\n",
    "    query_iso = np.random.choice(iso_list)  # starting node for query set\n",
    "    val_iso = np.random.choice(iso_list)  # starting node for validation set\n",
    "\n",
    "    query_set = get_connected_country_set(query_iso, border_map, max_size=max_query_size)\n",
    "    val_set = get_connected_country_set(val_iso, border_map, max_size=max_val_size)\n",
    "\n",
    "    if len(query_set) < min_query_size or len(val_set) < min_val_size:\n",
    "        continue\n",
    "\n",
    "    if query_set & val_set:\n",
    "        continue\n",
    "\n",
    "    n_runs += 1\n",
    "    backgnd_set = all_isos - query_set - val_set\n",
    "\n",
    "    backgnd_indices = np.array([i for i, iso in enumerate(iso_list) if iso in backgnd_set])\n",
    "    query_indices = np.array([i for i, iso in enumerate(iso_list) if iso in query_set])\n",
    "    val_indices = np.array([i for i, iso in enumerate(iso_list) if iso in val_set])\n",
    "\n",
    "    x_initial = df_year[\n",
    "    [\"Polio\", \"HIV/AIDS\", \"Diphtheria\", \"under-five deaths\"]\n",
    "    # [\"Alcohol\"]\n",
    "    # [\"thinness  1-19 years\"],\n",
    "    # [\"BMI\"],\n",
    "    ].to_numpy()\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    try:\n",
    "        results_relnet = train_relnet(\n",
    "            x=x_initial,\n",
    "            y=y,\n",
    "            r=R,\n",
    "            backgnd_indices=np.array(backgnd_indices),\n",
    "            query_indices=np.array(query_indices),\n",
    "            val_indices=np.array(val_indices),\n",
    "            lr=.01,\n",
    "            n_epochs=1500,\n",
    "            periodic_embed_dim=None,\n",
    "            progress_bar=True,\n",
    "            print_loss=False,\n",
    "            n_layers=2,\n",
    "            num_heads=2,\n",
    "            embed_dim=8,\n",
    "        )\n",
    "        relnet_mse, relnet_r2 = results_relnet[:2]\n",
    "        metrics[\"relnet_mse\"].append(relnet_mse)\n",
    "        metrics[\"relnet_r2\"].append(relnet_r2)\n",
    "    except Exception as e:\n",
    "         print(e)\n",
    "\n",
    "    continue\n",
    "\n",
    "    n_samples, n_feats = x_initial.shape\n",
    "\n",
    "    x_extended = np.concatenate([x_initial, R], axis=1)\n",
    "\n",
    "    for x, x_label in (\n",
    "         (x_initial, \"xInit\"), \n",
    "        #  (x_extended, \"xExtended\")\n",
    "         ):\n",
    "\n",
    "        x_mean = np.mean(x, axis=0, keepdims=True)\n",
    "        x_std = np.std(x, axis=0, keepdims=True)\n",
    "        x_norm = (x - x_mean) / x_std\n",
    "\n",
    "        r_torch = torch.Tensor(R)\n",
    "        x_torch = torch.Tensor(x_norm)\n",
    "        y_torch = torch.Tensor(y)\n",
    "\n",
    "        n_back = n_query = n_samples // 3\n",
    "        n_test = n_samples - (n_back + n_query)\n",
    "        x_back, y_back = x_torch[:n_back], y_torch[:n_back]\n",
    "        x_q, y_q = x_torch[n_back : n_query + n_back], y_torch[n_back : n_query + n_back]\n",
    "        x_val, y_val = x_torch[n_back + n_query :], y_torch[n_back + n_query :]\n",
    "        r_q_b = r_torch[n_back : n_query + n_back, :n_back]\n",
    "        \n",
    "        if x_label == \"xExtended\":\n",
    "            r_q_b = torch.zeros_like(r_q_b)\n",
    "        \n",
    "        r_val_b = r_torch[n_back + n_query :, :n_back]\n",
    "        # x_train, y_train = x_torch[: n_back + n_query], y_torch[: n_back + n_query]\n",
    "        # r_val_train = r_torch[n_back + n_query :, : n_back + n_query]\n",
    "\n",
    "        if x_label == \"xExtended\":\n",
    "                r_val_train = torch.zeros_like(r_val_train)\n",
    "\n",
    "        inds_back = np.array(range(n_back))\n",
    "        inds_q = np.array(range(n_query)) + n_back\n",
    "        inds_val = np.array(range(len(x) - n_query - n_back)) + n_query + n_back\n",
    "\n",
    "        try:\n",
    "             res = run_training(\n",
    "                  x=x, y=y, r=R,\n",
    "                  backgnd_indices=inds_back,\n",
    "                  query_indices=inds_q,\n",
    "                  val_indices=inds_val,\n",
    "                  lr=.005,\n",
    "                  n_epochs=100,\n",
    "                  rel_as_feats=R,\n",
    "             )\n",
    "             for k, v in res.items():\n",
    "                  mse, r2 = v[:2]\n",
    "                  metrics[f\"{k}_mse\"].append(mse)\n",
    "                  metrics[f\"{k}_r2\"].append(r2)\n",
    "        except Exception as e:\n",
    "             print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d528dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stats = []\n",
    "for k, v in metrics.items():\n",
    "    results_stats.append({\"name\": k, \n",
    "                          \"mean\": round(np.mean(v), 2),\n",
    "                          \"std\": round(np.std(v), 2)})\n",
    "    print(f\"{k}: {np.mean(v):.2f} & {np.std(v):.2f}\")\n",
    "# pd.DataFrame(results_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a48263e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in metrics.items():\n",
    "    if k.startswith(\"xInit\") and k.endswith(\"mse\"):\n",
    "        print(k, np.mean(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbedbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics[\"xInit_sigma0.5_rscale5_val_r2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f3e730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO try parameters grid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabrel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
